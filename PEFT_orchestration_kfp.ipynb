{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf11017-90e6-42ef-93cb-b6b676f514a3",
   "metadata": {},
   "source": [
    "# L3: Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d6585-d38d-4deb-9494-1706fc9253d9",
   "metadata": {},
   "source": [
    "- You will use [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/v2/) to orchestrate and automate a workflow. \n",
    "- Kubeflow Pipelines is an open source framework. It's like a construction kit for building machine learning pipelines, making it easy to orchestrate and automate complex tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fcd000-f502-47e5-b0db-809b9555f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "\n",
    "# Ignore FutureWarnings in kfp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        category=FutureWarning, \n",
    "                        module='kfp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294daf3a-41d6-4db2-84b0-bdab8f2acc0c",
   "metadata": {},
   "source": [
    "## Kubeflow Pipelines\n",
    "\n",
    "- Kubeflow pipelines consist of two key concepts: Components and pipelines.\n",
    "- Pipeline components are like self-contained sets of code that perform various steps in your ML workflow, such as, the first step could be preprocessing data, and second step could betraining a model.\n",
    "\n",
    "### Simple Pipeline Example \n",
    "\n",
    "##### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb4746f-21e0-4bb2-9e95-75aae4a0d1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Simple example: component 1\n",
    "@dsl.component\n",
    "def say_hello(name: str) -> str:\n",
    "    hello_text = f'Hello, {name}!'\n",
    "    \n",
    "    return hello_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cae0bd-91d1-453a-a307-fd06126449a7",
   "metadata": {},
   "source": [
    "- Since we \"wrapped\" this `say_hello` function in the decorator `@dsl.component`, the function will not actually return a string.\n",
    "- The function will return a `PipelineTask` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112251c7-9c87-45cd-acff-de847a3c7208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e80d4361fa0>\n"
     ]
    }
   ],
   "source": [
    "hello_task = say_hello(name=\"Erwin\")\n",
    "print(hello_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a9205-934e-4b4e-b5c7-f832b6debadf",
   "metadata": {},
   "source": [
    "- The object that we'll use to pass the information in `hello_text` to other components in the pipeline is `PipelineTask.output`, which will be a built-in data type:\n",
    "> `['String', 'Integer', 'Float', 'Boolean', 'List', 'Dict']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587b68a5-b6ec-4ebd-8a46-034684458d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{channel:task=say-hello;name=Output;type=String;}}\n"
     ]
    }
   ],
   "source": [
    "print(hello_task.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f75c7-e91a-4bed-beaa-e67dbb88953a",
   "metadata": {},
   "source": [
    "- Note when passing in values to the a `dsl.component` function, you have to specify the argument names (keyword arguments), and can't use positional arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea89276-bd5d-4ef3-b284-940678c18792",
   "metadata": {},
   "source": [
    "- The second component is dependent on the first component\n",
    "- Take the output of the first component and pass it to the second component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0df10f-ba15-4ab5-ae30-79d128d03770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Simple example: component 2\n",
    "@dsl.component\n",
    "def how_are_you(hello_text: str) -> str:\n",
    "    \n",
    "    how_are_you = f\"{hello_text}. How are you?\"\n",
    "    \n",
    "    return how_are_you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256fd9e-17e3-463c-b651-6c6d80dfdd46",
   "metadata": {},
   "source": [
    "- Notice that when we pass in the return value from the `say_hello` function, we want to pass in the PipelineTask.output object, and not the PipelineTask object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a018a4c9-2436-401e-9bd4-8332c0b26fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e80d4361b50>\n",
      "{{channel:task=how-are-you;name=Output;type=String;}}\n"
     ]
    }
   ],
   "source": [
    "how_task = how_are_you(hello_text=hello_task.output)\n",
    "print(how_task)\n",
    "print(how_task.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabdac2-d9e5-4b69-a80a-6da0320e67ad",
   "metadata": {},
   "source": [
    "- Define the pipeline.\n",
    "- Notice how the input to `say_hello` is just `recipient`, since that is already a built-in data type (a String).\n",
    "- Recall that to get the value from a PipelineTask object, you'll use `PipelineTask.output` to pass in that value to another Pipeline Component function.\n",
    "- Notice that Pipeline function should return the PipelineTask.output as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a4e200-a1a6-4262-a2af-565a535a5160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Simple example: pipeline\n",
    "@dsl.pipeline\n",
    "def hello_pipeline(recipient: str) -> str:\n",
    "    \n",
    "    # notice, just recipient and not recipient.output\n",
    "    hello_task = say_hello(name=recipient)\n",
    "    \n",
    "    # notice .output\n",
    "    how_task = how_are_you(hello_text=hello_task.output)\n",
    "    \n",
    "    # notice .output\n",
    "    return how_task.output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb31ba0-14a7-4be1-a9c7-8579cea026ed",
   "metadata": {},
   "source": [
    "- If you run this pipeline function, you'll see that the return value (`task.output` was a String) is again wrapped inside a PipelineTask object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a7c498-f58d-430d-8f55-a453acdfa210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e80d4239e20>\n"
     ]
    }
   ],
   "source": [
    "pipeline_output = hello_pipeline(recipient=\"Erwin\")\n",
    "print(pipeline_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a70ee-191d-4f7f-ae90-8f1fc1dc40f7",
   "metadata": {},
   "source": [
    "- Note that if you tried to return a PipelineTask object instead of the PipelineTask.output, you'd get an error message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f4c9a-ef44-45d1-8474-4aa0ed805180",
   "metadata": {},
   "source": [
    "##### Implement the pipeline\n",
    "\n",
    "- A pipeline is a set of components that you orchestrate.\n",
    "- It lets you define the order of execution and how data flows from one step to another.\n",
    "- Compile the pipeline into a yaml file, `pipeline.yaml`\n",
    "- You can look at the `pipeline.yaml` file in your workspace by going to `File --> Open...`. Or right here in the notebook (two cells below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9110c542-ab54-4573-af68-67961fb3f0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(hello_pipeline, 'test_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8c308-6c5b-427f-809d-5ff13c51cd99",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Define the arguments, the input that goes into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbbf9bb-9b1c-48fa-b3bd-377bfb77982f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"recipient\": \"World!\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42081e3d-8e8b-4672-a9e3-3d93695acb2c",
   "metadata": {},
   "source": [
    "- View the `test_pipeline.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dcbbe99-c886-4e03-8a72-633b76d8b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PIPELINE DEFINITION\n",
      "# Name: hello-pipeline\n",
      "# Inputs:\n",
      "#    recipient: str\n",
      "# Outputs:\n",
      "#    Output: str\n",
      "components:\n",
      "  comp-how-are-you:\n",
      "    executorLabel: exec-how-are-you\n",
      "    inputDefinitions:\n"
     ]
    }
   ],
   "source": [
    "!head test_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af790edc",
   "metadata": {},
   "source": [
    "- Load the Project ID and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94d476bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID, STAGING_BUCKET = authenticate() \n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15070570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "aiplatform.init(project = PROJECT_ID,\n",
    "                location = REGION,\n",
    "                credentials = credentials,\n",
    "                staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7268560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: llm-ft-bucket>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "storage_client = storage.Client(project=PROJECT_ID,credentials=credentials)\n",
    "list(storage_client.list_buckets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19471f4a-7691-47bc-b963-9e830fae8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 You do not have permission to act as service_account: 735245711206-compute@developer.gserviceaccount.com. (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"You do not have permission to act as service_account: 735245711206-compute@developer.gserviceaccount.com. (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.70.42:443 {grpc_message:\"You do not have permission to act as service_account: 735245711206-compute@developer.gserviceaccount.com. (or it may not exist).\", grpc_status:3, created_time:\"2025-06-13T13:43:09.436758497+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53485/3782480391.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m### submit for execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m### check to see the status of the job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         self._run(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mOptional\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         self.submit(\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, service_account, network, reserved_ip_ranges, create_request_timeout, experiment)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_create_with_lro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         self._gca_resource = self.api_client.create_pipeline_job(\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mpipeline_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/cloud/aiplatform_v1/services/pipeline_service/client.py\u001b[0m in \u001b[0;36mcreate_pipeline_job\u001b[0;34m(self, request, parent, pipeline_job, pipeline_job_id, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/dl-ai-llmops/.venv/lib/python3.8/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 You do not have permission to act as service_account: 735245711206-compute@developer.gserviceaccount.com. (or it may not exist)."
     ]
    }
   ],
   "source": [
    "### import `PipelineJob` \n",
    "from google.cloud.aiplatform import PipelineJob\n",
    "\n",
    "job = PipelineJob(\n",
    "        ### path of the yaml file to execute\n",
    "        template_path=\"test_pipeline.yaml\",\n",
    "        ### name of the pipeline\n",
    "        display_name=f\"test_pipeline\",\n",
    "        ### pipeline arguments (inputs)\n",
    "        ### {\"recipient\": \"World!\"} for this example\n",
    "        parameter_values=pipeline_arguments,\n",
    "        ### region of execution\n",
    "        location=REGION,\n",
    "        ### root is where temporary files are being \n",
    "        ### stored by the execution engine\n",
    "        pipeline_root= f\"gs://{STAGING_BUCKET}/\",\n",
    ")\n",
    "\n",
    "### submit for execution\n",
    "job.run()\n",
    "\n",
    "### check to see the status of the job\n",
    "#job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4334e-8c76-49e0-9b6b-309fe3cbc204",
   "metadata": {},
   "source": [
    "### Real-life Pipeline Example \n",
    "\n",
    "#### Automation and Orchestration of a Supervised Tuning Pipeline.\n",
    "\n",
    "- Reuse an existing Kubeflow Pipeline for Parameter-Efficient Fine-Tuning (PEFT) for a foundation model from Google, called [PaLM 2](https://ai.google/discover/palm2/). \n",
    "- Advantage of reusing a pipleline means you do not have to build it from scratch, you can only specify some of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88178549-83df-4fa8-9554-a42e96558d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### these are the same \n",
    "### jsonl files from the previous lab\n",
    "\n",
    "### time stamps have been removed so that \n",
    "### the files are consistent for all learners\n",
    "TRAINING_DATA_URI = \"./train_data_stack_overflow_python_qa.jsonl\" \n",
    "EVAUATION_DATA_URI = \"./eval_data_stack_overflow_python_qa.jsonl\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd1f73-9818-4e91-99e2-12bd5b02ca03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### path to the pipeline file to reuse\n",
    "### the file is provided in your workspace as well\n",
    "template_path = 'https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0a586-56df-4628-a6c7-b5b823b7168e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")\n",
    "\n",
    "MODEL_NAME = f\"deep-learning-ai-model-{date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ab578-ac94-419d-813f-162251258e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "- This example uses two PaLM model parameters:\n",
    "  - `TRAINING_STEPS`: Number of training steps to use when tuning the model. For extractive QA you can set it from 100-500. \n",
    "  - `EVALUATION_INTERVAL`: The interval determines how frequently a trained model is evaluated against the created *evaluation set* to assess its performance and identify issues. Default will be 20, which means after every 20 training steps, the model is evaluated on the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a637b-6f50-478d-8a58-8e0fc3b8b8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_STEPS = 200\n",
    "EVALUATION_INTERVAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc079e-5244-4421-9648-a9640b823388",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Define the arguments, the input that goes into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8deddf9-abad-403d-9780-0a4b4ecbca41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"model_display_name\": MODEL_NAME,\n",
    "    \"location\": REGION,\n",
    "    \"large_model_reference\": \"text-bison@001\",\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"train_steps\": TRAINING_STEPS,\n",
    "    \"dataset_uri\": TRAINING_DATA_URI,\n",
    "    \"evaluation_interval\": EVALUATION_INTERVAL,\n",
    "    \"evaluation_data_uri\": EVAUATION_DATA_URI,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf05e9-40d2-474d-9d43-c9e644bf6053",
   "metadata": {},
   "source": [
    "```Python\n",
    "pipeline_root \"./\"\n",
    "\n",
    "job = PipelineJob(\n",
    "        ### path of the yaml file to execute\n",
    "        template_path=template_path,\n",
    "        ### name of the pipeline\n",
    "        display_name=f\"deep_learning_ai_pipeline-{date}\",\n",
    "        ### pipeline arguments (inputs)\n",
    "        parameter_values=pipeline_arguments,\n",
    "        ### region of execution\n",
    "        location=REGION,\n",
    "        ### root is where temporary files are being \n",
    "        ### stored by the execution engine\n",
    "        pipeline_root=pipeline_root,\n",
    "        ### enable_caching=True will save the outputs \n",
    "        ### of components for re-use, and will only re-run those\n",
    "        ### components for which the code or data has changed.\n",
    "        enable_caching=True,\n",
    ")\n",
    "\n",
    "### submit for execution\n",
    "job.submit()\n",
    "\n",
    "### check to see the status of the job\n",
    "job.state\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facc65c-f84b-40e8-876e-b2faa2a61135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b61034-7243-4e03-8a46-9ef89a70bdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
